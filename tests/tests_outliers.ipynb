{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType\n",
    "from pyspark.sql.functions import *\n",
    "import utils\n",
    "import numeric_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Nulls and Outliers Detection 1\") \\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_temp = df = spark.read.csv(path = 'GROUP7/bss9-579f_clean/part-00000-919430be-1ef9-4fee-9d5f-c8cac19198b3-c000.csv', header = True,inferSchema = True, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df_temp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparable_rental_2_gross_sqft   counts: 45   counts % = 9.375%\n",
      "brooklyn_condominiums_comparable_properties_estimated_expense   counts: 46   counts % = 9.583333333333334%\n",
      "brooklyn_condominiums_comparable_properties_total_units   counts: 48   counts % = 10.0%\n",
      "brooklyn_condominiums_comparable_properties_expense_per_sqft   counts: 5   counts % = 1.0416666666666665%\n",
      "comparable_rental_2_gross_income_per_sqft   counts: 9   counts % = 1.875%\n",
      "comparable_rental_1_gross_income_per_sqft   counts: 4   counts % = 0.8333333333333334%\n",
      "comparable_rental_1_estimated_expense   counts: 53   counts % = 11.041666666666666%\n",
      "comparable_rental_1_net_operating_income   counts: 63   counts % = 13.125%\n",
      "comparable_rental_2_estimated_expense   counts: 52   counts % = 10.833333333333334%\n",
      "brooklyn_condominiums_comparable_properties_gross_sqft   counts: 45   counts % = 9.375%\n",
      "brooklyn_condominiums_comparable_properties_market_value_per_sqft   counts: 3   counts % = 0.625%\n",
      "brooklyn_condominiums_comparable_properties_gross_income_per_sqft   counts: 8   counts % = 1.6666666666666667%\n",
      "comparable_rental_2_estimated_gross_income   counts: 59   counts % = 12.291666666666666%\n",
      "comparable_rental_2_year_built   counts: 63   counts % = 13.125%\n",
      "brooklyn_condominiums_comparable_properties_full_market_value   counts: 53   counts % = 11.041666666666666%\n",
      "comparable_rental_2_distance_from_condo_in_miles   counts: 51   counts % = 10.625%\n",
      "comparable_rental_1_estimated_gross_income   counts: 66   counts % = 13.750000000000002%\n",
      "brooklyn_condominiums_comparable_properties_net_operating_income   counts: 52   counts % = 10.833333333333334%\n",
      "comparable_rental_1_year_built   counts: 104   counts % = 21.666666666666668%\n",
      "comparable_rental_3_distance_from_condo_in_miles   counts: 48   counts % = 10.0%\n",
      "comparable_rental_1_expense_per_sqft   counts: 1   counts % = 0.20833333333333334%\n",
      "comparable_rental_3_market_value_per_sqft   counts: 12   counts % = 2.5%\n",
      "brooklyn_condominiums_comparable_properties_estimated_gross_income   counts: 50   counts % = 10.416666666666668%\n",
      "comparable_rental_1_full_market_value   counts: 59   counts % = 12.291666666666666%\n",
      "comparable_rental_2_expense_per_sqft   counts: 0   counts % = 0.0%\n",
      "comparable_rental_3_year_built   counts: 73   counts % = 15.208333333333332%\n",
      "comparable_rental_3_expense_per_sqft   counts: 3   counts % = 0.625%\n",
      "comparable_rental_1_total_units   counts: 60   counts % = 12.5%\n",
      "comparable_rental_1_market_value_per_sqft   counts: 1   counts % = 0.20833333333333334%\n",
      "comparable_rental_2_total_units   counts: 53   counts % = 11.041666666666666%\n",
      "comparable_rental_2_full_market_value   counts: 36   counts % = 7.5%\n",
      "brooklyn_condominiums_comparable_properties_year_built   counts: 93   counts % = 19.375%\n",
      "comparable_rental_1_distance_from_condo_in_miles   counts: 41   counts % = 8.541666666666666%\n",
      "comparable_rental_3_total_units   counts: 35   counts % = 7.291666666666667%\n",
      "comparable_rental_2_net_operating_income   counts: 40   counts % = 8.333333333333332%\n",
      "comparable_rental_1_gross_sqft   counts: 70   counts % = 14.583333333333334%\n",
      "comparable_rental_2_market_value_per_sqft   counts: 14   counts % = 2.9166666666666665%\n",
      "comparable_rental_3_gross_income_per_sqft   counts: 16   counts % = 3.3333333333333335%\n"
     ]
    }
   ],
   "source": [
    "keyval = {}\n",
    "df_temp = df_temp.withColumn(\"rid\", monotonically_increasing_id())\n",
    "for col,dtype in df_temp.dtypes:\n",
    "    if 'string' not in dtype and col!='rid':\n",
    "        \n",
    "        keyval[col] = numeric_outliers.get_outliers(df_temp,col)\n",
    "        print(col , \"  counts:\",keyval[col].count(),'  counts % = {}%'.format(100*(keyval[col].count()/df_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import KMeans, KMeansModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col = df_temp.select(df_temp['rid'],df_temp['comparable_rental_2_gross_sqft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-13889c573bfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_vect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comparable_rental_2_gross_sqft'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1182\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1183\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "df_vect = df_temp.map(lambda x: np.array(float(x['comparable_rental_2_gross_sqft'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------------+\n",
      "|(rid = 0)|comparable_rental_2_gross_sqft|\n",
      "+---------+------------------------------+\n",
      "|     true|                        109875|\n",
      "|    false|                          9875|\n",
      "|    false|                         39770|\n",
      "|    false|                         39770|\n",
      "|    false|                         39770|\n",
      "|    false|                        108780|\n",
      "|    false|                         28358|\n",
      "|    false|                          9875|\n",
      "|    false|                         28358|\n",
      "|    false|                         31692|\n",
      "|    false|                         60720|\n",
      "|    false|                         73032|\n",
      "|    false|                         39770|\n",
      "|    false|                         39770|\n",
      "|    false|                         39770|\n",
      "|    false|                         15200|\n",
      "|    false|                         27144|\n",
      "|    false|                          8600|\n",
      "|    false|                         21040|\n",
      "|    false|                          8600|\n",
      "+---------+------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_temp.select(df_temp['rid'] == 0,df_temp['comparable_rental_2_gross_sqft']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(rid=0, comparable_rental_2_gross_sqft=109875),\n",
       " Row(rid=1, comparable_rental_2_gross_sqft=9875),\n",
       " Row(rid=2, comparable_rental_2_gross_sqft=39770),\n",
       " Row(rid=3, comparable_rental_2_gross_sqft=39770),\n",
       " Row(rid=4, comparable_rental_2_gross_sqft=39770)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_col_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vso = df_col_rdd.map(lambda x: np.array(float(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = KMeans.train(vso,3,initializationMode='random',maxIterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters.centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addclustercols(x):\n",
    "    point = np.array(float(x[1]))\n",
    "    center = clusters.centers[0]\n",
    "    mindist = np.abs(point - center)\n",
    "    c1 = 0\n",
    "    for i in range(1,len(clusters.centers)):\n",
    "        center = clusters.centers[i]\n",
    "        dist = np.abs(point - center)\n",
    "        if dist < mindist:\n",
    "            c1 = i\n",
    "            mindist = dist\n",
    "    return (int(x[0]),float(x[1]),int(c1),float(mindist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd_w_clusts = df_col_rdd.map(lambda x: addclustercols(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = 'comparable_rental_2_gross_sqft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_df = spark.createDataFrame(rdd_w_clusts,('rid',col,'c_no','dist_c'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outliers = numeric_outliers.get_outliers(kmeans_df,'dist_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers.count()/df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_data = sc.textFile('GROUP7/bss9-579f_clean/part-00000-919430be-1ef9-4fee-9d5f-c8cac19198b3-c000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
